# Chat Juicer Environment Variables
# Copy this file to .env and fill in your actual values

# ====================================
# API Provider Selection
# ====================================
# Choose which API to use: "azure" or "openai"
# Default: azure
API_PROVIDER=azure

# ====================================
# Azure OpenAI Configuration
# ====================================
# Get these from your Azure OpenAI resource in Azure Portal

# Your Azure OpenAI API key
AZURE_OPENAI_API_KEY=your-azure-api-key-here

# Your Azure OpenAI endpoint (format: https://YOUR_RESOURCE_NAME.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# Your deployment name (must support Responses API)
AZURE_OPENAI_DEPLOYMENT=your-deployment-name

# ====================================
# OpenAI Configuration (Alternative)
# ====================================
# Get your API key from platform.openai.com/api-keys

# Your OpenAI API key
OPENAI_API_KEY=your-openai-api-key-here

# Model to use (e.g., gpt-4, gpt-4-turbo, gpt-3.5-turbo)
OPENAI_MODEL=gpt-5

# ====================================
# Reasoning Configuration
# ====================================
# Control reasoning effort for reasoning models (gpt-5, o1, o3)
# Options: minimal, low, medium, high
# - minimal: Fastest responses, fewest reasoning tokens (cheapest)
# - low: Light reasoning
# - medium: Balanced (default, recommended for most use cases)
# - high: Maximum thoroughness, most reasoning tokens (most expensive)
REASONING_EFFORT=medium

# ====================================
# MCP Server Configuration
# ====================================
# Tavily API key for web search MCP server
# Get your free API key from https://tavily.com (1000 searches/month free)
# Tools provided: tavily-search, tavily-extract, tavily-map, tavily-crawl
TAVILY_API_KEY=your-tavily-api-key-here

# ====================================
# General Settings
# ====================================
# Disable telemetry/tracking (recommended for privacy)
OPENAI_AGENTS_DISABLE_TRACING=true

# Enable HTTP request/response logging (for debugging API issues)
# WARNING: Logs full request payloads including all conversation context
# Only enable when troubleshooting - produces very verbose logs
HTTP_REQUEST_LOGGING=false

# Database (adjust host port if 5432 is in use)
DATABASE_URL=postgresql://chatjuicer:localdev@localhost:5432/chatjuicer
# DATABASE_URL=postgresql://chatjuicer:localdev@localhost:5433/chatjuicer

# File storage
FILE_STORAGE=local
FILE_STORAGE_PATH=data/files

# API server
API_PORT=8000
API_HOST=0.0.0.0

# ====================================
# Connection Pool Configuration
# ====================================
# PostgreSQL connection pool sizing
# - DB_POOL_MIN_SIZE: Minimum idle connections (default: 2)
# - DB_POOL_MAX_SIZE: Maximum connections (default: 10)
# For cloud deployments with many concurrent users, increase max_size
DB_POOL_MIN_SIZE=2
DB_POOL_MAX_SIZE=10

# MCP server pool sizing
# - MCP_POOL_SIZE: Instances per server type (default: 3)
# - MCP_ACQUIRE_TIMEOUT: Timeout in seconds to acquire a server (default: 30.0)
# Increase pool_size for high-concurrency deployments
MCP_POOL_SIZE=3
MCP_ACQUIRE_TIMEOUT=30.0

# HTTP client timeouts for Azure OpenAI streaming
# Reasoning models (GPT-5, O1, O3) can pause 30+ seconds while "thinking"
# Default 600s (10 min) handles even complex reasoning tasks
HTTP_READ_TIMEOUT=600.0

# Auth
DEFAULT_USER_EMAIL=local@chatjuicer.dev
ALLOW_LOCALHOST_NOAUTH=true
JWT_SECRET=dev-change-me
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRES_MINUTES=15
REFRESH_TOKEN_EXPIRES_DAYS=7
