# Chat Juicer Environment Variables
# Copy this file to .env and fill in your actual values
#
# Configuration Loading Order (later files override earlier):
# 1. .env (base defaults - this file after copying)
# 2. .env.{APP_ENV} (.env.development, .env.production, .env.test)
# 3. .env.local (local overrides, gitignored)
#
# Set APP_ENV to control which environment config to load:
# - development (default): Local development with hot-reload support
# - production: Production settings with stricter validation
# - test: Test environment for automated testing

# ====================================
# Environment Selection
# ====================================
APP_ENV=development

# Enable hot-reloading of configuration (development only)
# When true, settings are reloaded on each request to pick up .env changes
CONFIG_HOT_RELOAD=false

# ====================================
# API Provider Selection
# ====================================
# Choose which API to use: "azure" or "openai"
# Default: azure
API_PROVIDER=azure

# ====================================
# Azure OpenAI Configuration
# ====================================
# Get these from your Azure OpenAI resource in Azure Portal

# Your Azure OpenAI API key
AZURE_OPENAI_API_KEY=your-azure-api-key-here

# Your Azure OpenAI endpoint (format: https://YOUR_RESOURCE_NAME.openai.azure.com/)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# ====================================
# OpenAI Configuration (Alternative)
# ====================================
# Only needed if API_PROVIDER=openai
# Get your API key from platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# Note: Model and reasoning effort are selected per-session in the UI.
# Defaults are configured in core/constants.py (DEFAULT_MODEL, DEFAULT_REASONING_EFFORT)

# ====================================
# MCP Server Configuration
# ====================================
# Tavily API key for web search MCP server
# Get your free API key from https://tavily.com (1000 searches/month free)
# Tools provided: tavily-search, tavily-extract, tavily-map, tavily-crawl
TAVILY_API_KEY=your-tavily-api-key-here

# ====================================
# General Settings
# ====================================
# Disable telemetry/tracking (recommended for privacy)
OPENAI_AGENTS_DISABLE_TRACING=true

# Enable HTTP request/response logging (for debugging API issues)
# WARNING: Logs full request payloads including all conversation context
# Only enable when troubleshooting - produces very verbose logs
HTTP_REQUEST_LOGGING=false

# Database (adjust host port if 5432 is in use)
DATABASE_URL=postgresql://chatjuicer:localdev@localhost:5432/chatjuicer
# DATABASE_URL=postgresql://chatjuicer:localdev@localhost:5433/chatjuicer

# File storage
FILE_STORAGE=local
FILE_STORAGE_PATH=data/files

# API server
API_PORT=8000
API_HOST=0.0.0.0

# ====================================
# Connection Pool Configuration
# ====================================
# PostgreSQL connection pool sizing
# - DB_POOL_MIN_SIZE: Minimum idle connections (default: 2)
# - DB_POOL_MAX_SIZE: Maximum connections (default: 10)
# For cloud deployments with many concurrent users, increase max_size
DB_POOL_MIN_SIZE=2
DB_POOL_MAX_SIZE=10

# MCP server pool sizing
# - MCP_POOL_SIZE: Instances per server type (default: 3)
# - MCP_ACQUIRE_TIMEOUT: Timeout in seconds to acquire a server (default: 30.0)
# Increase pool_size for high-concurrency deployments
MCP_POOL_SIZE=3
MCP_ACQUIRE_TIMEOUT=30.0

# HTTP client timeouts for Azure OpenAI streaming
# Reasoning models (GPT-5, O1, O3) can pause 30+ seconds while "thinking"
# Default 600s (10 min) handles even complex reasoning tasks
HTTP_READ_TIMEOUT=600.0

# Auth
DEFAULT_USER_EMAIL=local@chatjuicer.dev
ALLOW_LOCALHOST_NOAUTH=true
# Generate a secure secret with: openssl rand -hex 32
JWT_SECRET=CHANGE_ME_generate_with_openssl_rand_hex_32
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRES_MINUTES=15
REFRESH_TOKEN_EXPIRES_DAYS=7
